# Promtail configuration for Docker container log collection
# Collects logs from Docker containers via Docker logging driver
# Extracts trace IDs for Grafana/Tempo integration

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Docker container discovery - automatically discovers and collects logs from all containers
  - job_name: docker-containers
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          # Only collect logs from containers matching these name patterns
          - name: name
            values: ['.*easyflow.*', '.*rpa-system.*', '.*automation.*']
    
    relabel_configs:
      # Extract container name (remove leading slash)
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: container_name
        replacement: '${1}'
      
      # Map container names to job names for better organization
      - source_labels: [__meta_docker_container_name]
        regex: '.*(easyflow-backend|rpa-system-backend).*'
        target_label: job
        replacement: 'easyflow-backend'
      
      - source_labels: [__meta_docker_container_name]
        regex: '.*(easyflow-frontend|rpa-dashboard).*'
        target_label: job
        replacement: 'easyflow-frontend'
      
      - source_labels: [__meta_docker_container_name]
        regex: '.*(automation-worker|automation-service).*'
        target_label: job
        replacement: 'easyflow-automation'
      
      # Default job name if no match (use container name)
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: job
        replacement: '${1}'
      
      # Set service label based on job
      - source_labels: [job]
        target_label: service
        replacement: '${1}'
      
      # Set environment label
      - target_label: environment
        replacement: 'development'
      
      # Set the log path to Docker container JSON log file (stdout/stderr)
      - source_labels: [__meta_docker_container_id]
        target_label: __path__
        replacement: '/var/lib/docker/containers/${1}/${1}-json.log'
    
    pipeline_stages:
      # Stage 0: Parse Docker's JSON log format
      # Docker wraps each log line in JSON: {"log":"...","stream":"stdout","time":"..."}
      # Extract the actual application log content from Docker's wrapper
      - json:
          expressions:
            docker_log: log
            docker_stream: stream
            docker_time: time
      
      # Replace the current line with the extracted application log for further processing
      # This makes the application log the new line content
      - replace:
          expression: '.*'
          replace: '${docker_log}'
      
      # Stage 1: JSON parsing - Most efficient method for structured logs
      # Try to parse log as JSON and extract traceId from trace.traceId field
      - json:
          expressions:
            level: level
            msg: msg
            time: time
            timestamp: timestamp
            service: service
            logger: logger
            trace_id: trace.traceId  # Primary extraction: from JSON structure
            span_id: trace.spanId
            user_id: trace.userId
            method: trace.method
            path: trace.path
            execution_id: error.execution_id
            workflow_id: error.workflow_id
      
      # Stage 2: Regex fallback - Extract trace ID if JSON parsing didn't find it
      # This handles non-JSON logs or logs where traceId is in a different format
      # Looks for any 32-character hexadecimal string (standard trace ID format)
      - regex:
          expression: '(?P<trace_id_fallback>[0-9a-fA-F]{32})'
          source: msg
      
      # Merge: Use JSON-extracted trace_id if available, otherwise use regex fallback
      - template:
          source: trace_id
          template: '{{ if .trace_id }}{{ .trace_id }}{{ else if .trace_id_fallback }}{{ .trace_id_fallback }}{{ end }}'
      
      # Stage 3: Trace stage - Extract trace_id as internal field (label) for Loki
      # This tells Loki to treat trace_id as a trace identifier, making it discoverable by Grafana
      # The label enables fast filtering: {trace_id="75ae2874a1cf402204aa76b473332b6f"}
      - labels:
          level:
          service:
          logger:
          trace_id: # Index trace_id as a label - enables fast filtering and trace discovery
      
      # Stage 4: Timestamp handling - Ensure logs have correct timestamps
      # CRITICAL FIX: Prevent timestamp overwriting and handle Unix milliseconds correctly
      # 
      # Problem: Pino's 'time' field is Unix milliseconds (e.g., 1765929045350), not seconds
      # If parsed as Unix seconds, it's interpreted as a future date and overwrites correct timestamps
      # 
      # Solution: Use action_on_failure: fallback to chain timestamp parsing
      # Priority order (stops at first successful parse):
      # 1. Docker's timestamp (RFC3339Nano) - Most reliable, represents actual log capture time
      # 2. Application timestamp field (RFC3339 ISO format from Pino) - Fallback if Docker time missing
      # 3. Application time field (UnixMs - milliseconds) - Fallback if timestamp field missing
      # 
      # action_on_failure: fallback tells Promtail to only proceed to the next stage if the current
      # one fails. This prevents the 'time' field from overwriting correct timestamps when parsed
      # incorrectly as Unix seconds instead of milliseconds.
      - timestamp:
          source: docker_time
          format: RFC3339Nano
          action_on_failure: fallback
      - timestamp:
          source: timestamp
          format: RFC3339
          action_on_failure: fallback
      - timestamp:
          source: time
          format: UnixMs  # Pino's time field is in milliseconds, not seconds
          action_on_failure: skip
      
      # Stage 5: Output formatting - Add traceId to log content for Grafana derived fields
      # This ensures trace IDs are present in log content for Tempo trace discovery
      # Grafana's derived fields will extract this and link to Tempo
      - template:
          source: output
          template: '{{ .msg }}{{ if .trace_id }} traceId="{{ .trace_id }}"{{ end }}'
      
      - output:
          source: output
