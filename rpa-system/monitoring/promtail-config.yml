# Promtail configuration for Docker container log collection
# Collects logs from Docker containers via Docker logging driver
# Extracts trace IDs for Grafana/Tempo integration

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Docker container discovery - automatically discovers and collects logs via Docker API
  # CRITICAL: Using Docker API directly (not file tailing) eliminates filesystem buffering delays
  # This ensures logs are captured in real-time without the 5-10 second delay from file I/O buffering
  # By NOT setting __path__ to a file path, Promtail uses Docker's API to stream logs directly
  # 
  # Note: No name filters - relabel_configs below handle categorization more robustly
  # This ensures we don't accidentally miss logs from new services
  - job_name: easyflow-services
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    
    relabel_configs:
      # Extract container name (remove leading slash)
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: container_name
        replacement: '${1}'
      
      # Map container names to job names for better organization
      - source_labels: [__meta_docker_container_name]
        regex: '.*(easyflow-backend|rpa-system-backend).*'
        target_label: job
        replacement: 'easyflow-backend'
      
      - source_labels: [__meta_docker_container_name]
        regex: '.*(easyflow-frontend|rpa-dashboard).*'
        target_label: job
        replacement: 'easyflow-frontend'
      
      - source_labels: [__meta_docker_container_name]
        regex: '.*(automation-worker|automation-service).*'
        target_label: job
        replacement: 'easyflow-automation'
      
      # Default job name if no match (use container name)
      - source_labels: [__meta_docker_container_name]
        regex: '/(.*)'
        target_label: job
        replacement: '${1}'
      
      # Set service label based on job
      - source_labels: [job]
        target_label: service
        replacement: '${1}'
      
      # Set environment label
      - target_label: environment
        replacement: 'development'
      
      # CRITICAL: Do NOT set __path__ to a file path
      # By omitting __path__, Promtail uses Docker's API directly to stream logs
      # This eliminates filesystem buffering delays and provides real-time log capture
      # The docker_sd_configs automatically provides the correct target for Docker API log streaming
    
    pipeline_stages:
      # Stage 0: Parse Docker's JSON log format
      # Docker wraps each log line in JSON: {"log":"<application log>","stream":"stdout","time":"<timestamp>"}
      # Extract Docker wrapper fields AND preserve them for timestamp parsing
      - json:
          expressions:
            docker_log: log
            docker_stream: stream
            docker_time: time
      
      # Stage 1: Parse application log JSON without discarding Docker fields
      # Parse the docker_log field as JSON to extract application log fields
      # CRITICAL: Using source: docker_log preserves docker_time field from Stage 0
      # Rename application timestamps to app_time and app_timestamp to avoid conflicts
      - json:
          source: docker_log
          expressions:
            level: level
            msg: msg
            app_time: time  # Renamed to avoid conflict with docker_time
            app_timestamp: timestamp  # Renamed to avoid conflict with docker_time
            service: service
            logger: logger
            trace_id: trace.traceId  # Primary extraction: from JSON structure
            span_id: trace.spanId
            user_id: trace.userId
            method: trace.method
            path: trace.path
            execution_id: error.execution_id
            workflow_id: error.workflow_id
      
      # Stage 2: Regex fallback - Extract trace ID if JSON parsing didn't find it
      # This handles non-JSON logs or logs where traceId is in a different format
      # Looks for any 32-character hexadecimal string (standard trace ID format)
      - regex:
          expression: '(?P<trace_id_fallback>[0-9a-fA-F]{32})'
          source: msg
      
      # Merge: Use JSON-extracted trace_id if available, otherwise use regex fallback
      - template:
          source: trace_id
          template: '{{ if .trace_id }}{{ .trace_id }}{{ else if .trace_id_fallback }}{{ .trace_id_fallback }}{{ end }}'
      
      # Stage 3: Trace stage - Extract trace_id as internal field (label) for Loki
      # This tells Loki to treat trace_id as a trace identifier, making it discoverable by Grafana
      # The label enables fast filtering: {trace_id="75ae2874a1cf402204aa76b473332b6f"}
      - labels:
          level:
          service:
          logger:
          trace_id: # Index trace_id as a label - enables fast filtering and trace discovery
      
      # Stage 4: Timestamp handling - Ensure logs have correct timestamps
      # CRITICAL FIX: Use Docker's timestamp as primary source (most accurate)
      # 
      # Priority order (stops at first successful parse):
      # 1. Docker's timestamp (RFC3339Nano) - Most reliable, represents actual log capture time
      # 2. Application timestamp field (RFC3339 ISO format from Pino) - Fallback if Docker time missing
      # 3. Application time field (UnixMs - milliseconds) - Fallback if timestamp field missing
      # 
      # action_on_failure: fallback tells Promtail to only proceed to the next stage if the current
      # one fails. This ensures docker_time is used when available, providing the most accurate timestamp.
      - timestamp:
          source: docker_time
          format: RFC3339Nano
          action_on_failure: fallback
      - timestamp:
          source: app_timestamp
          format: RFC3339
          action_on_failure: fallback
      - timestamp:
          source: app_time
          format: UnixMs  # Pino's time field is in milliseconds, not seconds
          action_on_failure: skip
      
      # Stage 5: Output formatting - Add traceId to log content for Grafana derived fields
      # This ensures trace IDs are present in log content for Tempo trace discovery
      # Grafana's derived fields will extract this and link to Tempo
      - template:
          source: output
          template: '{{ .msg }}{{ if .trace_id }} traceId="{{ .trace_id }}"{{ end }}'
      
      - output:
          source: output
