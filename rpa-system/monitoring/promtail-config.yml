# Promtail configuration for log collection
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
# Backend JSON logs
- job_name: easyflow-backend
  static_configs:
  - targets:
      - localhost
    labels:
      job: easyflow-backend
      service: rpa-system-backend
      environment: development
      __path__: /app/logs/backend*.log
  
  pipeline_stages:
  # Stage 1: JSON parsing - Most efficient method for structured logs
  # Try to parse log as JSON and extract traceId from trace.traceId field
  - json:
      expressions:
        level: level
        msg: msg
        time: time
        timestamp: timestamp
        service: service
        logger: logger
        trace_id: trace.traceId  # Primary extraction: from JSON structure
        span_id: trace.spanId
        user_id: trace.userId
        method: trace.method
        path: trace.path
        execution_id: error.execution_id
        workflow_id: error.workflow_id
  # Stage 2: Regex fallback - Extract trace ID if JSON parsing didn't find it
  # This handles non-JSON logs or logs where traceId is in a different format
  # Looks for any 32-character hexadecimal string (standard trace ID format)
  # Only extract if trace_id wasn't already set by JSON stage
  - regex:
      expression: '(?P<trace_id_fallback>[0-9a-fA-F]{32})'
      source: msg
  # Merge: Use JSON-extracted trace_id if available, otherwise use regex fallback
  - template:
      source: trace_id
      template: '{{ if .trace_id }}{{ .trace_id }}{{ else if .trace_id_fallback }}{{ .trace_id_fallback }}{{ end }}'
  # Stage 3: Trace stage - Extract trace_id as internal field (label) for Loki
  # This tells Loki to treat trace_id as a trace identifier, making it discoverable by Grafana
  # The label enables fast filtering: {trace_id="75ae2874a1cf402204aa76b473332b6f"}
  - labels:
      level:
      service:
      logger:
      trace_id: # Index trace_id as a label - enables fast filtering and trace discovery
  # Stage 4: Timestamp handling - Ensure logs have correct timestamps
  # Try ISO format first (from timestamp field), fallback to Unix (from time field)
  - timestamp:
      source: timestamp
      format: RFC3339
  - timestamp:
      source: time
      format: Unix
  # Stage 5: Output formatting - Add traceId to log content for Grafana derived fields
  # This ensures trace IDs are present in log content for Tempo trace discovery
  # Grafana's derived fields will extract this and link to Tempo
  - template:
      source: output
      template: '{{ .msg }}{{ if .trace_id }} traceId="{{ .trace_id }}"{{ end }}'
  - output:
      source: output

# Frontend logs
- job_name: easyflow-frontend
  static_configs:
  - targets:
      - localhost
    labels:
      job: easyflow-frontend
      service: rpa-system-frontend
      environment: development
      __path__: /app/logs/frontend*.log
  
  pipeline_stages:
  - timestamp:
      source: time
      format: RFC3339
  - output:
      source: msg

# Automation worker logs (Python with timestamp prefix)
- job_name: easyflow-automation
  static_configs:
  - targets:
      - localhost
    labels:
      job: easyflow-automation
      service: automation-worker
      environment: development
      __path__: /app/logs/automation-worker*.log
  
  pipeline_stages:
  # Extract timestamp and content from Python logs
  - regex:
      expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}): (?P<content>.*)'
  - labels:
      log_level: info
  - match:
      selector: '{job="easyflow-automation"}'
      stages:
      - regex:
          expression: '.*(?i)(error|exception|failed|traceback).*'
      - labels:
          log_level: error
  - timestamp:
      source: timestamp
      format: '2006-01-02 15:04:05'
  - output:
      source: content

# Backend error logs
- job_name: easyflow-backend-errors
  static_configs:
  - targets:
      - localhost
    labels:
      job: easyflow-backend-errors
      service: rpa-system-backend
      environment: development
      log_level: error
      __path__: /app/logs/backend-error*.log
  
  pipeline_stages:
  # Parse JSON error logs
  - json:
      expressions:
        level: level
        msg: msg
        time: time
        service: service
        error: error
        stack: stack
  - labels:
      level:
      service:
  - timestamp:
      source: time
      format: Unix
  - output:
      source: msg

# Frontend error logs
- job_name: easyflow-frontend-errors
  static_configs:
  - targets:
      - localhost
    labels:
      job: easyflow-frontend-errors
      service: rpa-system-frontend
      environment: development
      log_level: error
      __path__: /app/logs/frontend-error*.log
  
  pipeline_stages:
  - timestamp:
      source: time
      format: RFC3339
  - output:
      source: msg

